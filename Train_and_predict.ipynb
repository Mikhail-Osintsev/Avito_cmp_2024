{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import gc\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "import shap\n",
    "import catboost\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем директорию для сохранения моделей\n",
    "save_dir = 'saved_models'\n",
    "# Создаем папку для моделей, если она не существует\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Определяем директорию для сохранения результатов предсказаний\n",
    "output_folder = \"results_folder\"\n",
    "# Создаем папку для результатов, если она не существует\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Определяем пути для сохранения результатов предсказаний\n",
    "output_file_path_1 = os.path.join(output_folder, \"result_1.csv\")\n",
    "output_file_path_2 = os.path.join(output_folder, \"result_2.csv\")\n",
    "output_file_path_3 = os.path.join(output_folder, \"result_3.csv\")\n",
    "\n",
    "# Определяем директорию, где хранятся разделенные данные\n",
    "data_dir = \"data_split\"\n",
    "\n",
    "# Определяем полные пути к файлам тренировочных и тестовых данных для каждого блока\n",
    "train_path_1 = os.path.join(data_dir, \"train_block_1.parquet\")\n",
    "test_path_1 = os.path.join(data_dir, \"test_block_1.parquet\")\n",
    "\n",
    "train_path_2 = os.path.join(data_dir, \"train_block_2.parquet\")\n",
    "test_path_2 = os.path.join(data_dir, \"test_block_2.parquet\")\n",
    "\n",
    "train_path_3 = os.path.join(data_dir, \"train_block_3.parquet\")\n",
    "test_path_3 = os.path.join(data_dir, \"test_block_3.parquet\")\n",
    "\n",
    "# Определяем полные пути для сохранения каждой модели CatBoost\n",
    "catboost_model_path_1 = os.path.join(save_dir, 'catboost_model_1.cbm')\n",
    "catboost_model_path_2 = os.path.join(save_dir, 'catboost_model_2.cbm')\n",
    "catboost_model_path_3 = os.path.join(save_dir, 'catboost_model_3.cbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_for_training(dataset, test_data, block_name, target_col='target', reduce_frac=0.1):\n",
    "    \"\"\"\n",
    "    Фильтрует тренировочные данные для обучения модели, сохраняя все примеры с target = 1, \n",
    "    а также совпадающие примеры по указанной комбинации ключей в зависимости от блока.\n",
    "    Из оставшихся данных с target = 0 случайным образом выбирает заданную долю.\n",
    "\n",
    "    Параметры:\n",
    "    - dataset: DataFrame с тренировочными данными.\n",
    "    - test_data: DataFrame с тестовыми данными для проверки совпадающих ключей.\n",
    "    - block_name: Название блока ('train_block_1', 'train_block_2', или 'train_block_3').\n",
    "    - target_col: Название столбца с целевой переменной.\n",
    "    - reduce_frac: Доля данных с target = 0, которые нужно оставить.\n",
    "\n",
    "    Возвращает:\n",
    "    - DataFrame с отфильтрованными данными.\n",
    "    \"\"\"\n",
    "\n",
    "    # Определяем ключи для каждого блока\n",
    "    if block_name == 'train_block_1':\n",
    "        keys = ['user_id', 'logcat_id', 'adv_campaign_id']\n",
    "    elif block_name == 'train_block_2':\n",
    "        keys = ['user_id', 'logcat_id']\n",
    "    elif block_name == 'train_block_3':\n",
    "        keys = None  # Для train_block_3 не нужны ключи\n",
    "    else:\n",
    "        raise ValueError(\"Некорректное значение block_name. Ожидается 'train_block_1', 'train_block_2' или 'train_block_3'.\")\n",
    "\n",
    "    # Шаг 1: Отбираем все данные с target = 1\n",
    "    target_one_data = dataset[dataset[target_col] == 1]\n",
    "\n",
    "    if keys:\n",
    "        # Шаг 2: Определяем уникальные комбинации ключей в тестовом наборе\n",
    "        test_keys = test_data[keys].drop_duplicates()\n",
    "        \n",
    "        # Шаг 3: Отбираем совпадающие по ключам записи из тренировочных данных\n",
    "        matching_data = dataset.merge(test_keys, on=keys, how='inner')\n",
    "        \n",
    "        # Шаг 4: Отбираем оставшиеся данные с target = 0, которые не входят в matching_data\n",
    "        target_zero_data = dataset[(dataset[target_col] == 0) & (~dataset.index.isin(matching_data.index))]\n",
    "        \n",
    "        # Шаг 5: Случайным образом выбираем reduce_frac от оставшихся данных с target = 0\n",
    "        target_zero_sampled = target_zero_data.sample(frac=reduce_frac, random_state=42)\n",
    "        \n",
    "        # Объединяем данные с target = 1, совпадающие по ключам, и случайную выборку оставшихся данных с target = 0\n",
    "        filtered_data = pd.concat([target_one_data, matching_data, target_zero_sampled])\n",
    "    else:\n",
    "        # Если блок `train_block_3`, то только отбираем target = 1 и случайную выборку\n",
    "        target_zero_data = dataset[dataset[target_col] == 0]\n",
    "        target_zero_sampled = target_zero_data.sample(frac=reduce_frac, random_state=42)\n",
    "        filtered_data = pd.concat([target_one_data, target_zero_sampled])\n",
    "    \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_catboost_model(dataset):\n",
    "    # Фильтруем данные для обучения на основе дат\n",
    "    train_data = dataset\n",
    "\n",
    "    # Разделяем признаки и целевую переменную\n",
    "    X_train = train_data.drop(columns=['user_id', 'target', 'event_date'])  # Исключаем идентификаторы и target\n",
    "    y_train = train_data['target']\n",
    "    \n",
    "    # Подготовка Pool объектов для CatBoost с учетом категориальных фичей\n",
    "    cat_features = ['day_of_week']  # Укажите категориальные признаки\n",
    "    train_pool = Pool(data=X_train, label=y_train, cat_features=cat_features)\n",
    "    \n",
    "    # Учет дисбаланса классов с использованием scale_pos_weight\n",
    "    # Используем соотношение классов в тренировочном наборе\n",
    "    scale_pos_weight = len(y_train[y_train == 0]) / max(1, len(y_train[y_train == 1]))\n",
    "\n",
    "    # Инициализация и обучение модели CatBoost\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=300,\n",
    "        learning_rate=0.1,\n",
    "        depth=6,\n",
    "        eval_metric='AUC',  # Метрика на обучении\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        early_stopping_rounds=50,   # Ранняя остановка на обучении\n",
    "        use_best_model=False,       # Отключаем выбор лучшей модели на валидации\n",
    "        random_seed=42,\n",
    "        verbose=100\n",
    "        )\n",
    "    \n",
    "    # Обучение модели на всех данных\n",
    "    model.fit(train_pool)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные train для блока 1\n",
    "train_block_1 = pd.read_parquet(train_path_1)\n",
    "test_block_1 = pd.read_parquet(test_path_1)\n",
    "\n",
    "# Применяем фильтрацию к обучающим данным\n",
    "train_block_1 = filter_data_for_training(train_block_1, test_block_1, 'train_block_1')\n",
    "\n",
    "# Шаг 1: Удалите ссылку на DataFrame\n",
    "del test_block_1\n",
    "\n",
    "# Шаг 2: Принудительно вызовите сборщик мусора\n",
    "gc.collect()\n",
    "\n",
    "# Определяем столбцы, которые будут использоваться в модели для train и test данных\n",
    "columns_to_keep_train = [\n",
    "    'user_id',  'target', 'day_of_week', 'goal_cost', \n",
    "    'goal_budget_day', 'event_date', 'user_ad_count', \n",
    "    'cumulative_shows_user_campaign_logcat', 'click_rate_adv_logcat', \n",
    "    'logcat_campaign_click_rate', 'days_since_campaign_start', \n",
    "    'daily_ad_count', 'days_since_last_interaction_adv_logcat'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Фильтруем данные, оставляя только нужные столбцы\n",
    "train_block_1 = train_block_1[columns_to_keep_train]\n",
    "\n",
    "# Обучаем модель на train_block_1\n",
    "model_1 = train_catboost_model(train_block_1)\n",
    "\n",
    "# Сохраняем модель в указанный путь\n",
    "model_1.save_model(catboost_model_path_1)\n",
    "\n",
    "# Шаг 1: Удалите ссылку на DataFrame\n",
    "del train_block_1\n",
    "\n",
    "# Шаг 2: Принудительно вызовите сборщик мусора\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные train для блока 2\n",
    "train_block_2 = pd.read_parquet(train_path_2)\n",
    "test_block_2 = pd.read_parquet(test_path_2)\n",
    "\n",
    "train_block_2 = filter_data_for_training(train_block_2, test_block_2, 'train_block_2')\n",
    "\n",
    "# Шаг 1: Удалите ссылку на DataFrame\n",
    "del test_block_2\n",
    "\n",
    "# Шаг 2: Принудительно вызовите сборщик мусора\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Определяем столбцы, которые будут использоваться в модели для train и test данных\n",
    "columns_to_keep_train = [\n",
    "    'user_id', 'event_date', 'target', 'day_of_week', \n",
    "    'goal_budget_day', 'user_ad_count', 'cumulative_shows_logcat', \n",
    "    'click_rate_logcat', 'logcat_click_rate', 'days_since_campaign_start', \n",
    "    'daily_ad_count_logcat', 'days_since_last_interaction_logcat'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Фильтруем данные, оставляя только нужные столбцы\n",
    "train_block_2 = train_block_2[columns_to_keep_train]\n",
    "\n",
    "# Обучаем модель на train_block_2\n",
    "model_2 = train_catboost_model(train_block_2)\n",
    "\n",
    "# Сохраняем модель в указанный путь\n",
    "model_2.save_model(catboost_model_path_2)\n",
    "\n",
    "# Шаг 1: Удалите ссылку на DataFrame\n",
    "del train_block_2\n",
    "\n",
    "# Шаг 2: Принудительно вызовите сборщик мусора\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные train для блока 3\n",
    "train_block_3 = pd.read_parquet(train_path_3)\n",
    "test_block_3 = pd.read_parquet(test_path_3)\n",
    "\n",
    "train_block_3 = filter_data_for_training(train_block_3, test_block_3, 'train_block_3')\n",
    "\n",
    "# Шаг 1: Удалите ссылку на DataFrame\n",
    "del test_block_3\n",
    "\n",
    "# Шаг 2: Принудительно вызовите сборщик мусора\n",
    "gc.collect()\n",
    "\n",
    "# Определяем необходимые столбцы для train и test данных\n",
    "columns_to_keep_train = [\n",
    "    'user_id', 'event_date', 'target', 'day_of_week', \n",
    "    'goal_budget_day', 'user_ad_count', 'click_rate', 'logcat_click_rate', \n",
    "    'days_since_campaign_start'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Оставляем только нужные столбцы в train_block_3 и test_block_3\n",
    "train_block_3 = train_block_3[columns_to_keep_train]\n",
    "\n",
    "# Обучаем модель на train_block_3\n",
    "model_3 = train_catboost_model(train_block_3)\n",
    "\n",
    "# Сохраняем модель в указанный путь\n",
    "model_3.save_model(catboost_model_path_3)\n",
    "\n",
    "# Шаг 1: Удалите ссылку на DataFrame\n",
    "del train_block_3\n",
    "\n",
    "# Шаг 2: Принудительно вызовите сборщик мусора\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = CatBoostClassifier()\n",
    "model_1.load_model(catboost_model_path_1)\n",
    "model_2 = CatBoostClassifier()\n",
    "model_2.load_model(catboost_model_path_2)\n",
    "model_3 = CatBoostClassifier()\n",
    "model_3.load_model(catboost_model_path_3)\n",
    "\n",
    "\n",
    "\n",
    "def predict_with_model(model, test_data, user_id_col='user_id', adv_campaign_id_col='adv_campaign_id'):\n",
    "    # Определяем категориальные фичи\n",
    "    cat_features = ['day_of_week']\n",
    "    \n",
    "    # Создаем Pool для тестовых данных с учетом cat_features\n",
    "    test_pool = Pool(data=test_data.drop(columns=[user_id_col, adv_campaign_id_col]), cat_features=cat_features)\n",
    "    \n",
    "    # Выполняем предсказание вероятности для положительного класса\n",
    "    test_data['predict'] = model.predict_proba(test_pool)[:, 1]\n",
    "    \n",
    "    # Возвращаем только необходимые столбцы\n",
    "    return test_data[[user_id_col, adv_campaign_id_col, 'predict']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка и выбор нужных столбцов для каждого блока тестовых данных\n",
    "columns_to_keep_test_1 = [\n",
    "    'user_id','adv_campaign_id', 'day_of_week', 'goal_cost', \n",
    "    'goal_budget_day', 'user_ad_count', 'cumulative_shows_user_campaign_logcat', \n",
    "    'click_rate_adv_logcat', 'logcat_campaign_click_rate', \n",
    "    'days_since_campaign_start', 'daily_ad_count', \n",
    "    'days_since_last_interaction_adv_logcat'\n",
    "]\n",
    "\n",
    "test_block_1 = pd.read_parquet(test_path_1)\n",
    "test_block_1 = test_block_1[columns_to_keep_test_1]\n",
    "\n",
    "columns_to_keep_test_2 = [\n",
    "    'user_id', 'adv_campaign_id', 'day_of_week', 'goal_budget_day', \n",
    "    'user_ad_count', 'cumulative_shows_logcat', 'click_rate_logcat', \n",
    "    'logcat_click_rate', 'days_since_campaign_start', 'daily_ad_count_logcat', \n",
    "    'days_since_last_interaction_logcat'\n",
    "]\n",
    "\n",
    "test_block_2 = pd.read_parquet(test_path_2)\n",
    "test_block_2 = test_block_2[columns_to_keep_test_2]\n",
    "\n",
    "columns_to_keep_test_3 = [\n",
    "    'user_id','adv_campaign_id', 'day_of_week', 'goal_budget_day', \n",
    "    'days_since_campaign_start', 'user_ad_count', 'click_rate', 'logcat_click_rate'\n",
    "]\n",
    "\n",
    "test_block_3 = pd.read_parquet(test_path_3)\n",
    "test_block_3 = test_block_3[columns_to_keep_test_3]\n",
    "\n",
    "# Убедитесь, что day_of_week является категориальной фичей\n",
    "test_block_1['day_of_week'] = test_block_1['day_of_week'].astype('category')\n",
    "test_block_2['day_of_week'] = test_block_2['day_of_week'].astype('category')\n",
    "test_block_3['day_of_week'] = test_block_3['day_of_week'].astype('category')\n",
    "\n",
    "# Выполняем предсказание после преобразования типов\n",
    "# Получаем предсказания для каждого блока и сохраняем их в соответствующие файлы\n",
    "result_1 = predict_with_model(model_1, test_block_1)\n",
    "result_1.to_csv(output_file_path_1, index=False)  # Сохраняем результат для блока 1\n",
    "\n",
    "result_2 = predict_with_model(model_2, test_block_2)\n",
    "result_2.to_csv(output_file_path_2, index=False)  # Исправлено: сохраняем результат для блока 2\n",
    "\n",
    "result_3 = predict_with_model(model_3, test_block_3)\n",
    "result_3.to_csv(output_file_path_3, index=False)  # Исправлено: сохраняем результат для блока 3\n",
    "\n",
    "# Объединяем предсказания из всех блоков в один DataFrame\n",
    "submission = pd.concat([result_1, result_2, result_3], ignore_index=True)\n",
    "\n",
    "# Сохраняем объединённый результат в файл submission.csv\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Файл submission.csv успешно сохранен.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_importance(model, X_train, model_name):\n",
    "    \"\"\"\n",
    "    Выводит важность признаков и строит графики SHAP для указанной модели.\n",
    "    \n",
    "    Параметры:\n",
    "    - model: обученная модель CatBoostClassifier\n",
    "    - X_train: тренировочный набор данных (без столбцов user_id, target, event_date)\n",
    "    - model_name: имя модели (для отображения в графиках)\n",
    "    \"\"\"\n",
    "    # Получаем важность признаков из CatBoost\n",
    "    feature_importances = model.get_feature_importance(type=\"FeatureImportance\")\n",
    "    feature_names = X_train.columns\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importances\n",
    "    }).sort_values(by=\"Importance\", ascending=False)\n",
    "    \n",
    "    # Выводим таблицу важности признаков\n",
    "    print(f\"\\nВажность признаков для {model_name}:\")\n",
    "    print(importance_df)\n",
    "    \n",
    "    # Строим график важности признаков\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    importance_df.plot(kind='barh', x='Feature', y='Importance', legend=False, title=f'Feature Importance for {model_name}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "    \n",
    "    # Оценка важности признаков с помощью SHAP\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    \n",
    "    print(f\"\\nSHAP Summary Plot for {model_name}:\")\n",
    "    shap.summary_plot(shap_values, X_train, plot_type=\"bar\", show=False)\n",
    "    plt.title(f\"SHAP Feature Importance for {model_name}\")\n",
    "    plt.show()\n",
    "    \n",
    "    #print(f\"\\nSHAP Beeswarm Plot for {model_name}:\")\n",
    "    #shap.summary_plot(shap_values, X_train, show=False)\n",
    "    #plt.title(f\"SHAP Feature Influence for {model_name}\")\n",
    "    #plt.show()\n",
    "\n",
    "# Загружаем данные train для блока 1\n",
    "train_block_1 = pd.read_parquet(train_path_1)\n",
    "test_block_1 = pd.read_parquet(test_path_1)\n",
    "train_block_1 = filter_data_for_training(train_block_1, test_block_1, 'train_block_1')\n",
    "del test_block_1\n",
    "gc.collect()\n",
    "columns_to_keep_train_1 = [\n",
    "    'user_id', 'target', 'day_of_week', 'goal_cost', \n",
    "    'goal_budget_day', 'event_date', 'user_ad_count', \n",
    "    'cumulative_shows_user_campaign_logcat', 'click_rate_adv_logcat', \n",
    "    'logcat_campaign_click_rate', 'days_since_campaign_start', \n",
    "    'daily_ad_count', 'days_since_last_interaction_adv_logcat'\n",
    "]\n",
    "train_block_1 = train_block_1[columns_to_keep_train_1]\n",
    "\n",
    "train_block_2 = pd.read_parquet(train_path_2)\n",
    "test_block_2 = pd.read_parquet(test_path_2)\n",
    "train_block_2 = filter_data_for_training(train_block_2, test_block_2, 'train_block_2')\n",
    "del test_block_2\n",
    "gc.collect()\n",
    "columns_to_keep_train_2 = [\n",
    "    'user_id',  'event_date', 'target', 'day_of_week', \n",
    "    'goal_budget_day', 'user_ad_count', 'cumulative_shows_logcat', \n",
    "    'click_rate_logcat', 'logcat_click_rate', 'days_since_campaign_start', \n",
    "    'daily_ad_count_logcat', 'days_since_last_interaction_logcat'\n",
    "]\n",
    "train_block_2 = train_block_2[columns_to_keep_train_2]\n",
    "\n",
    "train_block_3 = pd.read_parquet(train_path_3)\n",
    "test_block_3 = pd.read_parquet(test_path_3)\n",
    "train_block_3 = filter_data_for_training(train_block_3, test_block_3, 'train_block_3')\n",
    "del test_block_3\n",
    "gc.collect()\n",
    "columns_to_keep_train_3 = [\n",
    "    'user_id', 'event_date', 'target', 'day_of_week', \n",
    "    'goal_budget_day', 'user_ad_count', 'click_rate', 'logcat_click_rate', \n",
    "    'days_since_campaign_start'\n",
    "]\n",
    "train_block_3 = train_block_3[columns_to_keep_train_3]\n",
    "\n",
    "##\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вызываем функцию для каждой модели и соответствующего тренировочного набора\n",
    "print(\"Анализ важности признаков для model_1:\")\n",
    "analyze_feature_importance(model_1, train_block_1.drop(columns=['user_id', 'target', 'event_date']), \"Model 1\")\n",
    "\n",
    "print(\"Анализ важности признаков для model_2:\")\n",
    "analyze_feature_importance(model_2, train_block_2.drop(columns=['user_id', 'target', 'event_date']), \"Model 2\")\n",
    "\n",
    "print(\"Анализ важности признаков для model_3:\")\n",
    "analyze_feature_importance(model_3, train_block_3.drop(columns=['user_id', 'target', 'event_date']), \"Model 3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_venv",
   "language": "python",
   "name": "new_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
